{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ecb531-6113-4bde-a040-14f000b8fd64",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c6a303-a3b6-45fe-a6d9-36b4ae04f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leahheil/miniconda3/envs/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, TaskType\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    GenerationConfig,\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93adcfb-ac26-4f92-bed9-f7436b73b7da",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88976e9d-23e9-4464-8a95-5b1727774f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 2\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = True\n",
    "\n",
    "# Batch size per GPU for training and evaluation\n",
    "per_device_train_batch_size = 4\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "# max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c86150-e90c-4a8c-b66f-08abb3851858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1206c97a-13ca-48a1-9c89-5de249e5edc6",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a99abc-1aeb-4dc6-8152-0f7dd634aa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:12<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,048,576 || all params: 6,739,480,576 || trainable%: 0.015558706463730892\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "model_name = \"/home/leahheil/llama/weights\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})\n",
    "tokenizer.padding_side = \"left\" #TODO changed it to left because generate told me to, have not ran it with left\n",
    "\n",
    "# Load LLaMA model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\", quantization_config=bnb_config)\n",
    "model.config.pad_token_id = \"<pad>\"\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=2, # Rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules= [\"q_proj\",\"v_proj\"]\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=2)\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1fe0e7-435a-40be-b3c8-5417214ebd6a",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d4b4f0-0c6a-4ad8-93eb-aeb7a4a34d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/home/leahheil/dataset/dataset-annotated-train.csv\")\n",
    "df_val = pd.read_csv(\"/home/leahheil/dataset/dataset-annotated-val.csv\")\n",
    "df_test = pd.read_csv(\"/home/leahheil/dataset/dataset-annotated-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4114cfd4-9cab-4d01-afe5-b818265fda61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'prompt'],\n",
       "        num_rows: 404\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'prompt'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'prompt'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop indices and turn into dataset format\n",
    "data_train = df_train.reset_index(drop=True)\n",
    "data_test = df_test.reset_index(drop=True)\n",
    "data_val = df_val.reset_index(drop=True)\n",
    "data_train = Dataset.from_pandas(data_train)\n",
    "data_test = Dataset.from_pandas(data_test)\n",
    "data_val = Dataset.from_pandas(data_val)\n",
    "\n",
    "# create the datasetdict object\n",
    "data = DatasetDict()\n",
    "data['train'] = data_train\n",
    "data['test'] = data_test\n",
    "data['val'] = data_val\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30da5def-1762-4d9d-985b-ac9c20b59336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 404/404 [00:01<00:00, 246.51 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:00<00:00, 285.73 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:00<00:00, 279.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    prompt = [p for p in example[\"prompt\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=4096).input_ids\n",
    "    example['labels'] = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=4096).input_ids\n",
    "    return example\n",
    "\n",
    "dataset = data.map(tokenize_function, batched=True)\n",
    "dataset = dataset.remove_columns(['prompt', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275abdaa-4a3e-44be-aab1-44938aea6dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096]\n"
     ]
    }
   ],
   "source": [
    "dataset_lengths = []\n",
    "for i in dataset['val']:\n",
    "    dataset_lengths.append(len(i['input_ids']))\n",
    "print(dataset_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52857c-81b8-4da3-a50b-96a38106546e",
   "metadata": {},
   "source": [
    "# Set up Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "881ea05e-2736-494f-b036-ac068e19be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up peft trainer arguments\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=\"/home/leahheil/peft_output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"epoch\",\n",
    "    # auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    group_by_length=True,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    eval_accumulation_steps=1,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    max_grad_norm=max_grad_norm,\n",
    ")\n",
    "\n",
    "#TODO: try parameters from https://colab.research.google.com/drive/1SYpgFpcmtIUzdE7pxqknrM4ArCASfkFQ?usp=sharing#scrollTo=cxc8sr_4-7DM\n",
    "\n",
    "# Set up peft trainer\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"val\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0663babf-892d-462f-80fa-711bb4cefe0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [404/404 1:44:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=404, training_loss=2.083915937064898, metrics={'train_runtime': 6288.8611, 'train_samples_per_second': 0.064, 'train_steps_per_second': 0.064, 'total_flos': 3.3463681085865984e+16, 'train_loss': 2.083915937064898, 'epoch': 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5834b8c-708b-48e4-8044-77e1e879acaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/leahheil/notebooks/peft_output/checkpoint-404/tokenizer_config.json',\n",
       " '/home/leahheil/notebooks/peft_output/checkpoint-404/special_tokens_map.json',\n",
       " '/home/leahheil/notebooks/peft_output/checkpoint-404/tokenizer.json')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model\n",
    "peft_model_path=\"/home/leahheil/notebooks/peft_output/checkpoint-404\"\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)\n",
    "\n",
    "# trained_model = AutoModelForSeq2SeqLM.from_pretrained(\"/home/leahheil/peft_output/checkpoint-TODO\", torch_dtype=torch.bfloat16).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39f10847-2da4-443d-b613-e8670d4dbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_peft_model = PeftModel.from_pretrained(model, peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c97040f3-fd82-4e81-b1b3-f456c91a02ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 404\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef6a838a-7171-41f1-a2c5-1b67b8f9e75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline</th>\n",
       "      <th>original_model</th>\n",
       "      <th>peft_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wat je gaat doen․ Vervoer je graag bouwmateria...</td>\n",
       "      <td>Schrijf een vacature text voor Chauffeur bouwm...</td>\n",
       "      <td>Schrijf een vacature text voor Chauffeur bouwm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wat je gaat doen Wil jij werken als procesoper...</td>\n",
       "      <td>Schrijf een vacature text voor Procesoperator ...</td>\n",
       "      <td>Schrijf een vacature text voor Procesoperator ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wat je gaat doen Ben je technisch onderlegd en...</td>\n",
       "      <td>Schrijf een vacature text voor Operator Medica...</td>\n",
       "      <td>Schrijf een vacature text voor Operator Medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wat je gaat doen․ Zoek jij een baan met regelm...</td>\n",
       "      <td>Schrijf een vacature text voor Chauffeur koelt...</td>\n",
       "      <td>Schrijf een vacature text voor Chauffeur koelt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vacatureomschrijving․ Matchpartner Onderwijs z...</td>\n",
       "      <td>Schrijf een vacature text voor Docent Nederlan...</td>\n",
       "      <td>Schrijf een vacature text voor Docent Nederlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wat je gaat doen FrieslandCampina heeft een va...</td>\n",
       "      <td>Schrijf een vacature text voor Analyst Packagi...</td>\n",
       "      <td>Schrijf een vacature text voor Analyst Packagi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wat je gaat doen Lekker werken in de buitenluc...</td>\n",
       "      <td>Schrijf een vacature text voor Chauffeur vuiln...</td>\n",
       "      <td>Schrijf een vacature text voor Chauffeur vuiln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vacatureomschrijving․ Graduate Class Software ...</td>\n",
       "      <td>Schrijf een vacature text voor Graduate Class ...</td>\n",
       "      <td>Schrijf een vacature text voor Graduate Class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wat je gaat doen Wil jij lekker in de buitenlu...</td>\n",
       "      <td>Schrijf een vacature text voor Fulltime Magazi...</td>\n",
       "      <td>Schrijf een vacature text voor Fulltime Magazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vacatureomschrijving. De commercieel directeur...</td>\n",
       "      <td>Schrijf een vacature text voor Commercieel Dir...</td>\n",
       "      <td>Schrijf een vacature text voor Commercieel Dir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      human_baseline  \\\n",
       "0  Wat je gaat doen․ Vervoer je graag bouwmateria...   \n",
       "1  Wat je gaat doen Wil jij werken als procesoper...   \n",
       "2  Wat je gaat doen Ben je technisch onderlegd en...   \n",
       "3  Wat je gaat doen․ Zoek jij een baan met regelm...   \n",
       "4  Vacatureomschrijving․ Matchpartner Onderwijs z...   \n",
       "5  Wat je gaat doen FrieslandCampina heeft een va...   \n",
       "6  Wat je gaat doen Lekker werken in de buitenluc...   \n",
       "7  Vacatureomschrijving․ Graduate Class Software ...   \n",
       "8  Wat je gaat doen Wil jij lekker in de buitenlu...   \n",
       "9  Vacatureomschrijving. De commercieel directeur...   \n",
       "\n",
       "                                      original_model  \\\n",
       "0  Schrijf een vacature text voor Chauffeur bouwm...   \n",
       "1  Schrijf een vacature text voor Procesoperator ...   \n",
       "2  Schrijf een vacature text voor Operator Medica...   \n",
       "3  Schrijf een vacature text voor Chauffeur koelt...   \n",
       "4  Schrijf een vacature text voor Docent Nederlan...   \n",
       "5  Schrijf een vacature text voor Analyst Packagi...   \n",
       "6  Schrijf een vacature text voor Chauffeur vuiln...   \n",
       "7  Schrijf een vacature text voor Graduate Class ...   \n",
       "8  Schrijf een vacature text voor Fulltime Magazi...   \n",
       "9  Schrijf een vacature text voor Commercieel Dir...   \n",
       "\n",
       "                                          peft_model  \n",
       "0  Schrijf een vacature text voor Chauffeur bouwm...  \n",
       "1  Schrijf een vacature text voor Procesoperator ...  \n",
       "2  Schrijf een vacature text voor Operator Medica...  \n",
       "3  Schrijf een vacature text voor Chauffeur koelt...  \n",
       "4  Schrijf een vacature text voor Docent Nederlan...  \n",
       "5  Schrijf een vacature text voor Analyst Packagi...  \n",
       "6  Schrijf een vacature text voor Chauffeur vuiln...  \n",
       "7  Schrijf een vacature text voor Graduate Class ...  \n",
       "8  Schrijf een vacature text voor Fulltime Magazi...  \n",
       "9  Schrijf een vacature text voor Commercieel Dir...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = data['test'][0:10]['prompt']\n",
    "baseline_job_ads = data['test'][0:10]['text']\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "original_model_job_ads = []\n",
    "# instruct_model_job_ads = []\n",
    "peft_model_job_ads = []\n",
    "\n",
    "for idx, prompt in enumerate(prompts):\n",
    "    input_ids = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=4096).input_ids.to(device)\n",
    "\n",
    "    human_baseline_text_output = baseline_job_ads[idx]\n",
    "    \n",
    "    original_model_outputs = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=4096, pad_token_id=0))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=4096))\n",
    "    # instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    peft_model_outputs = trained_peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=4096, pad_token_id=0))\n",
    "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    original_model_job_ads.append(original_model_text_output)\n",
    "    # instruct_model_job_ads.append(instruct_model_text_output)\n",
    "    peft_model_job_ads.append(peft_model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(baseline_job_ads, original_model_job_ads, peft_model_job_ads))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline', 'original_model', 'peft_model'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "079162a5-4bfd-47fd-9fb8-fe49a0013a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schrijf een vacature text voor Chauffeur bouwmaterialen. Noem in iedergeval de volgende aspecten: \n",
      "- De functie omschrijving: Als chauffeur bouwmaterialen ben je verantwoordelijk voor het vervoeren van goederen naar klanten in de regio. Je laadt en lost de goederen en zorgt ervoor dat ze veilig worden vervoerd. Daarnaast heb je ook contact met de klanten en handel je het administratieve gedeelte af. De werkdag begint vroeg en eindigt in de middag, waardoor je een goede balans hebt tussen werk en privé.\n",
      "- De benodigde vaardigheden: Vereiste vaardigheden voor deze functie zijn een geldige bestuurderskaart, CE-rijbewijs met Code 95, ervaring met een kooi-aap of heftruck, ervaring met een trekker-oplegger en wonen in de omgeving van Den Haag, Rotterdam of Delft.\n",
      "- De arbeidsvoorwarden: Als chauffeur bouwmaterialen bij Start People Transport ontvang je een salaris tussen €2.100 en €2.700 bruto per maand op basis van ervaring. Daarnaast krijg je persoonlijke begeleiding, vakantiegeld, opbouw van verlofuren en pensioenopbouw. Het salaris wordt nauwkeurig uitbetaald op wekelijkse of vier-wekelijkse basis. Ook zijn er opleidingsmogelijkheden en een tijdelijk dienstverband met vaste uren.\n",
      "- De doelgroep: De doelgroep voor deze vacature zijn chauffeurs met ervaring in het vervoeren van bouwmaterialen en die wonen in de omgeving van Den Haag, Rotterdam of Delft.\n",
      "- De pull factoren: De pull factoren voor deze functie zijn het verdienen van een goed salaris, de mogelijkheid om door te groeien naar een vast dienstverband, persoonlijke begeleiding, flexibele uitbetaling van het salaris en opleidingsmogelijkheden.\n"
     ]
    }
   ],
   "source": [
    "print(df[\"peft_model\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1402152-772f-4519-b64b-0842f28987e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.config.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad5f9d2d-c840-4646-8d64-579c75796be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Schrijf een vacature text voor Chauffeur bouwmaterialen. Noem in iedergeval de volgende aspecten: \n",
      "- De functie omschrijving: Als chauffeur bouwmaterialen ben je verantwoordelijk voor het vervoeren van goederen naar klanten in de regio. Je laadt en lost de goederen en zorgt ervoor dat ze veilig worden vervoerd. Daarnaast heb je ook contact met de klanten en handel je het administratieve gedeelte af. De werkdag begint vroeg en eindigt in de middag, waardoor je een goede balans hebt tussen werk en privé.\n",
      "- De benodigde vaardigheden: Vereiste vaardigheden voor deze functie zijn een geldige bestuurderskaart, CE-rijbewijs met Code 95, ervaring met een kooi-aap of heftruck, ervaring met een trekker-oplegger en wonen in de omgeving van Den Haag, Rotterdam of Delft.\n",
      "- De arbeidsvoorwarden: Als chauffeur bouwmaterialen bij Start People Transport ontvang je een salaris tussen €2.100 en €2.700 bruto per maand op basis van ervaring. Daarnaast krijg je persoonlijke begeleiding, vakantiegeld, opbouw van verlofuren en pensioenopbouw. Het salaris wordt nauwkeurig uitbetaald op wekelijkse of vier-wekelijkse basis. Ook zijn er opleidingsmogelijkheden en een tijdelijk dienstverband met vaste uren.\n",
      "- De doelgroep: De doelgroep voor deze vacature zijn chauffeurs met ervaring in het vervoeren van bouwmaterialen en die wonen in de omgeving van Den Haag, Rotterdam of Delft.\n",
      "- De pull factoren: De pull factoren voor deze functie zijn het verdienen van een goed salaris, de mogelijkheid om door te groeien naar een vast dienstverband, persoonlijke begeleiding, flexibele uitbetaling van het salaris en opleidingsmogelijkheden.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n"
     ]
    }
   ],
   "source": [
    "def generate(prompt):\n",
    "    inputs = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=4096)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    generation_output = trained_peft_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=GenerationConfig(temperature=1.0, top_p=1.0, top_k=50, num_beams=1, pad_token_id=2),\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=2048\n",
    "    )\n",
    "    for seq in generation_output.sequences:\n",
    "        output = tokenizer.decode(seq)\n",
    "        print(output)\n",
    "generate(data[\"test\"][0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7c2a341-22c2-4111-8e11-84dd2dbbcde9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Instantiating a pipeline without a task set raised an error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/leahheil/llama/weights'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/env/lib/python3.10/site-packages/transformers/pipelines/__init__.py:443\u001b[0m, in \u001b[0;36mget_task\u001b[0;34m(model, token, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/leahheil/llama/weights'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/leahheil/notebooks/peft_output/checkpoint-404\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_full_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(pipe(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/env/lib/python3.10/site-packages/transformers/pipelines/__init__.py:762\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    759\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferring the task automatically requires to check the hub with a model_id defined as a `str`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    760\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid model_id.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    761\u001b[0m         )\n\u001b[0;32m--> 762\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[43mget_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;66;03m# Retrieve the task\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m custom_tasks:\n",
      "File \u001b[0;32m~/miniconda3/envs/env/lib/python3.10/site-packages/transformers/pipelines/__init__.py:445\u001b[0m, in \u001b[0;36mget_task\u001b[0;34m(model, token, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m     info \u001b[38;5;241m=\u001b[39m model_info(model, token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstantiating a pipeline without a task set raised an error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpipeline_tag:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not seem to have a correct `pipeline_tag` set to infer the task automatically\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Instantiating a pipeline without a task set raised an error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/leahheil/llama/weights'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(model=\"/home/leahheil/notebooks/peft_output/checkpoint-404\", return_full_text=False)\n",
    "print(pipe(data[\"test\"][0][\"prompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd965f5c-fe88-43d0-b83a-e10078f58bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
